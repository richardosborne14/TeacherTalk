# AI-Assisted Development - Quick Reference Card

> **Print this or keep it handy for daily reference**

---

## ðŸŽ¯ The 10 Commandments

1. **No Code Without Comments** (1 per 3-5 lines)
2. **Every File Has Header** (no exceptions)
3. **Explain "Why" Not "What"** (rationale over repetition)
4. **Document All Decisions** (in task files)
5. **Update After Milestones** (track progress)
6. **Confidence <8 = Review** (non-negotiable)
7. **Performance-Critical = Benchmark** (get numbers)
8. **Tests Tell Stories** (descriptive names)
9. **All Feedback Documented** (be specific)
10. **Slow Down and Think** (understanding beats speed)

---

## ðŸ“‹ Pre-Task Checklist

Before starting implementation:

- [ ] Read `.clinerules/implementation-standards.md`
- [ ] Check documentation guide for relevant sections
- [ ] Read only necessary doc sections
- [ ] Create task file in `.implementation/`
- [ ] State understanding of task
- [ ] Describe proposed approach
- [ ] Provide confidence rating with reasoning
- [ ] Get review if confidence <8

---

## ðŸ’» During Implementation

While coding:

- [ ] Write complete code (no "rest of the code" comments)
- [ ] Add comprehensive comments (target: 1 per 3-5 lines)
- [ ] Document design decisions as you make them
- [ ] Write tests alongside code
- [ ] Update task file after each milestone
- [ ] Re-assess confidence after major changes

---

## âœ… Pre-Completion Checklist

Before marking task complete:

### Documentation
- [ ] Every file has header
- [ ] Every class has documentation
- [ ] Every public method documented
- [ ] Code comments at 1:3-5 ratio
- [ ] Complex logic has diagrams

### Task Tracking
- [ ] All milestones documented
- [ ] All decisions recorded
- [ ] Challenges & solutions documented
- [ ] Confidence ratings with reasoning
- [ ] Files created/modified listed

### Testing
- [ ] Tests written and passing
- [ ] Test names are descriptive
- [ ] Coverage meets targets (80%+)
- [ ] Performance benchmarked (if critical)

### Review
- [ ] Human review done (if confidence <8)
- [ ] Feedback documented
- [ ] Lessons learned written

### Completion
- [ ] Success criteria met
- [ ] Next steps identified
- [ ] Final summary written

---

## ðŸ”¢ Confidence Scale

- **10** - Perfect, battle-tested
- **9** - Excellent, thoroughly tested
- **8** - Good, works well
- **7** - Solid, some concerns
- **6** - Acceptable, needs improvement
- **5** - Functional but concerning â†’ **REVIEW**
- **4** - Problematic â†’ **REVIEW**
- **3** - Serious issues â†’ **REVIEW**
- **2** - Barely working â†’ **REVIEW**
- **1** - Broken â†’ **REVIEW**

**<8 = MANDATORY HUMAN REVIEW**

---

## ðŸ“ File Header Template

```typescript
/**
 * @file [FileName].ts
 * @description [Purpose and role in system]
 * 
 * @architecture Phase [N], Task [N.N]
 * @created [YYYY-MM-DD]
 * @confidence [X/10] - [Reason]
 * 
 * @see [docs/file.md] - [Section]
 * @see [.implementation/task.md]
 * 
 * @security-critical [true/false]
 * @performance-critical [true/false]
 */
```

---

## ðŸ“š Class Documentation Template

```typescript
/**
 * [Class purpose]
 * 
 * PROBLEM SOLVED:
 * - [What problem]
 * 
 * SOLUTION:
 * - [How it solves it]
 * 
 * USAGE EXAMPLE:
 * ```typescript
 * [Example code]
 * ```
 * 
 * @class [ClassName]
 */
```

---

## ðŸ”§ Method Documentation Template

```typescript
/**
 * [Brief description]
 * 
 * ALGORITHM:
 * 1. [Step 1]
 * 2. [Step 2]
 * 
 * EDGE CASES:
 * - [Case and how handled]
 * 
 * @param [name] - [Description]
 * @returns [Description]
 * @throws {ErrorType} [When thrown]
 */
```

---

## ðŸ§ª Test Name Template

```typescript
describe('FeatureName', () => {
  it('should [expected behavior] when [condition]', () => {
    // test...
  });
});
```

**âœ… Good**: 
`should prevent infinite loop when tool generates file and watcher detects it`

**âŒ Bad**: 
`test file watcher`

---

## ðŸ“Š Performance Benchmark Template

```typescript
/**
 * Performance Benchmarks
 * 
 * Environment: [Your environment]
 * Date: [YYYY-MM-DD]
 * 
 * | Input Size | Time (avg) | Memory | Iterations |
 * |------------|------------|--------|------------|
 * | Small      | Xms        | YKB    | 1000       |
 * | Large      | Xms        | YKB    | 100        |
 * 
 * Target: [Your target]
 * Result: [Met/Not Met]
 */
```

---

## ðŸ” When to Benchmark

Benchmark when code is:
- Called frequently (>100 times/second)
- Handles large data (>1MB)
- On critical user path
- Part of identified bottleneck

---

## ðŸ‘¥ Human Review Triggers

**MANDATORY review when:**
- Confidence rating <8
- Security-critical code
- Architecture changes
- Performance-critical code
- Complex algorithms
- Edge case handling

---

## ðŸ“– Documentation Reading Strategy

**Don't**: Read all docs upfront
**Do**: Use documentation guide
**Read**: Only relevant sections
**When**: Just-in-time (while implementing)

**Example workflow:**
1. Check `.clinerules/documentation-guide.md`
2. Find your task type
3. Read listed sections only
4. Implement
5. Refer back only if needed

---

## ðŸ’¬ Common Phrases

### When Starting
"I'll implement [feature]. Let me start by:
1. Reading relevant documentation
2. Stating my understanding
3. Describing my approach
4. Providing confidence rating"

### When Uncertain
"Confidence: X/10 - [Specific concerns].
Would you like to review the approach before I proceed?"

### When Completing
"Implementation complete. Checklist verified:
âœ… Documentation complete
âœ… Tests passing (X tests, Y% coverage)
âœ… Task file updated
âœ… Review completed
Ready for merge."

---

## ðŸš¨ Red Flags - Stop and Ask

Stop immediately if:
- ðŸš¨ Confidence drops below 8
- ðŸš¨ Unclear requirements
- ðŸš¨ Security implications uncertain
- ðŸš¨ Architecture impact unclear
- ðŸš¨ Multiple approaches seem equally valid
- ðŸš¨ Edge cases not well understood
- ðŸš¨ Performance implications unknown

**Action**: Request human input before proceeding.

---

## ðŸŽ“ Comment Quality Examples

### âœ… Good Comments

```typescript
// Hash the file content to create a fingerprint we can 
// compare later. This lets us detect if the file changed 
// from what the tool generated.
const hash = crypto.createHash('sha256')
  .update(content)
  .digest('hex');

// Store expected hash before writing. After write completes,
// file watcher will compare actual vs expected hash.
this.generationHashes.set(filepath, hash);
```

### âŒ Bad Comments

```typescript
// Create hash
const hash = crypto.createHash('sha256').update(content).digest('hex');

// Set hash
this.generationHashes.set(filepath, hash);
```

---

## ðŸ—‚ï¸ Task File Structure

`.implementation/phase-X/task-X.Y.md`:

1. **Task Overview** - Objective, criteria, refs
2. **Milestones** - Steps with confidence
3. **Design Decisions** - Options, choice, rationale
4. **Implementation Notes** - Challenges, solutions
5. **Test Results** - Coverage, status
6. **Human Review** - Feedback, actions
7. **Lessons Learned** - Patterns, insights

---

## âš™ï¸ File Locations

```
.clinerules                    # Project root
â”œâ”€â”€ implementation-standards.md
â”œâ”€â”€ documentation-guide.md
â””â”€â”€ system-prompt.md

.implementation/
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ milestone-template.md
â””â”€â”€ phase-X/
    â””â”€â”€ task-X.Y.md

docs/
â”œâ”€â”€ ARCHITECTURE.md
â””â”€â”€ ...

src/
â””â”€â”€ ...
```

---

## ðŸŽ¯ Quick Decision Tree

```
Starting a task?
â”œâ”€ Read implementation standards
â”œâ”€ Check doc guide
â”œâ”€ Read relevant sections only
â”œâ”€ State understanding
â”œâ”€ Rate confidence
â”‚  â”œâ”€ <8? â†’ Get review
â”‚  â””â”€ â‰¥8? â†’ Proceed
â”œâ”€ Implement with full docs
â”œâ”€ Write tests
â”œâ”€ Update task file
â”œâ”€ Re-check confidence
â”‚  â”œâ”€ <8? â†’ Get review
â”‚  â””â”€ â‰¥8? â†’ Complete
â””â”€ Run pre-completion checklist
```

---

## ðŸ“ Quality Targets

- **Documentation headers**: 100%
- **Comment density**: 1:3-5 (comments:code)
- **Review rate**: 20-30%
- **Test coverage**: 80%+ critical paths
- **Rework rate**: <10% after review

---

## ðŸ”„ Daily Workflow

1. **Morning**: Review task list, prioritize
2. **Start task**: Read standards, check docs
3. **Implement**: Full documentation, tests
4. **Review**: Self-review, human if needed
5. **Complete**: Checklist, task file, merge
6. **End of day**: Update task status

---

## ðŸ’¡ Remember

**"Quality over speed.**
**Documentation over code.**
**Understanding over output."**

---

## ðŸ†˜ Troubleshooting Quick Fixes

### AI not following standards?
â†’ Check Cline custom instructions saved
â†’ Verify `.clinerules` files exist
â†’ Explicitly reference the standards

### Too many reviews?
â†’ Provide positive feedback when things go well
â†’ Break tasks smaller
â†’ Consider adjusting threshold

### Poor documentation?
â†’ Use specific examples from standards
â†’ Request: "Explain WHY not WHAT"
â†’ Point to good vs bad examples

### Context issues?
â†’ Use documentation guide
â†’ Break tasks into smaller chunks
â†’ Reference specific doc sections

---

## ðŸ“ž Quick Commands for AI

```
"Follow .clinerules/implementation-standards.md"
"What's your confidence rating? Explain reasoning."
"Add more comments explaining the rationale"
"Update the task file with this milestone"
"Please provide the implementation for review"
"Run the pre-completion checklist"
```

---

**Print this card and keep it visible while working!**

---

**Version 1.0 | November 2025**